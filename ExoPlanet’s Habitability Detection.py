# -*- coding: utf-8 -*-
"""ML Package (19PW11 - 19PW16).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fuFmjrpDBHGhqeqPHHY3Uo5R2Mz7VVSL

# DETECTION OF HABITABILITY IN EXOPLANETS
This machine learning project aims to predict if various exoplanets are habitable. The dataset used is **Nasa exoplanet archive**. This dataset contains has features such as the planet radius, stellar temperature, orbital period, and so on.

**Methodology**

1) Preprocessing 

2) Handling missing data

3) Normalizing

4) Exploratory data analysis

5) Defining models

6) Evaluation
"""

# Importing the necessary libraries
import pandas as pd
import numpy as np
import os
import math
import matplotlib.pyplot as plt
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import scipy.stats as stats
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import *
from sklearn.cluster import AgglomerativeClustering

# To remove columns with more than 20% missing data
def remove_missing(planets,f):
    count = len(planets[planets[f].isnull()])
    if count/len(planets) > 0.2:
        return 1
    else:
        return 0

# To calculate accuracy measures
def accuracyMeasures(yhat,yTest):
  TP,FP,TN,FN=0,0,0,0
  for j in range(0,len(yhat)):
    if yhat[j]==yTest[j]:
      if yhat[j]==1 and yTest[j]==1:
        TP+=1
      elif yhat[j]==0 and yTest[j]==0:
        TN+=1
    else:
      if yhat[j]==0 and yTest[j]==1:
        FN+=1
      elif yhat[j]==1 and yTest[j]==0:
        FP+=1
  confusionMatrix=[]
  positiveData=[]
  negativeData=[]
  positiveData.append(TP)
  positiveData.append(FN)
  negativeData.append(FP)
  negativeData.append(TN)
  confusionMatrix.append(positiveData)
  confusionMatrix.append(negativeData)
  print("\n\nConfusion Matrix:-")
  print(confusionMatrix)
  if (TP==0):
    precisionPositive= 0
  else:
    precisionPositive= TP/(TP+FP)
  if (TN==0):
    precisionNegative=0
  else:
    precisionNegative= TN/(TN+FN)
  
  if (TP==0):
    recallPositive=0
  else:
    recallPositive=TP/(TP+FN)
  if (TN==0):
    recallNegative=0
  else:
    recallNegative=TN/(TN+FP)
  
  if (precisionPositive*recallPositive==0):
    fScorePositive=0
  else:
    fScorePositive= 2*precisionPositive*recallPositive/(precisionPositive+recallPositive)
  if (precisionNegative*recallNegative==0):
    fScoreNegative=0
  else:
    fScoreNegative=2*precisionNegative*recallNegative/(precisionNegative+recallNegative)

  fpr,tpr,x=roc_curve(yTest,yhat)
  plt.plot(fpr,tpr)
  print("AUC: ", roc_auc_score(yTest,yhat))
  print("\nROC")

  return precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, roc_auc_score(yTest,yhat)

# List to contain model and its measures
eva_list = []
# To contain model names
models = []

# To test the model
def testModel(weights,xTest,yTest):
  accuracy=0
  yhat=[]
  for i in range(len(xTest)):
    yhat.append(predict(weights,xTest[i]))
    if yhat[i]==yTest[i]:
      accuracy+=1
  
  target_names = ['class 1', 'class 2']
  print(classification_report(yTest, yhat, target_names=target_names))
  precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC = accuracyMeasures(yhat,yTest)
  return (accuracy)/len(xTest), precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC

# Logistic regression functions
def sigmoid(wtx):
  return 1/(1+(math.exp(-1*wtx)))

def predict(w,x):
  if sigmoid(np.dot(w,x))>=0.5:
    return 1
  else:
    return 0

def logisticreg(x,y):
  convergence=False
  epoch=1
  weights=np.random.random(len(x[0]))
  while not convergence and epoch<=1000:
    convergence=True
    for i in range(len(x)):
      yhat=predict(weights,x[i])
      if yhat!= y[i]:
        convergence=False
        weights+= 0.001*(y[i]-sigmoid(np.dot(weights,x[i])))*x[i] 
    epoch+=1
    #print(weights)
  return weights

"""# Reading and preprocessing the dataset :-"""

df=pd.read_csv('Planet - cumulative.csv')

# Deleting features which have more than 20% missing value.
missing_values = [x for x in df.columns if remove_missing(df,x)]
df = df.drop(missing_values,axis=1)
df=df.drop(["koi_tce_delivname","koi_disposition","koi_pdisposition","rowid"],axis=1)

# Deleting rows which have no value for a field.
df = df.dropna()

# Removing features with more than 10 unique values.
cols = [x for x in df.columns if x not in df._get_numeric_data().columns]
for i in cols:
    if(len(df[i].unique()) > 10):
        df = df.drop(i, axis=1)

df. isna(). sum()

#xData= df[df.columns.difference(['koi_score'])].to_numpy()
#yData=df['koi_score'].to_numpy()

"""DIMENSIONALITY REDUCTION

"""

from sklearn.feature_selection import f_regression
ffs = f_regression(df,df.koi_period )

#removing irrelavant features
variable = [ ]
for i in range(0,len(df.columns)-1):
    if ffs[0][i] >=10:
       variable.append(df.columns[i])

#relevant features
variable

len(variable)

xData = df[variable]
xData = xData[xData.columns.difference(['koi_score'])].to_numpy()
yData=df['koi_score'].to_numpy()

"""After applying feature selection, choose top two most relevant features, and then create a scatter plot for EDA."""

plt.figure(figsize=(10, 7))  
plt.scatter(df[variable[0]], df[variable[1]])
plt.xlabel('koi_score')
plt.ylabel('koi_fpflag_nt')
plt.legend()
plt.show()

# Z- score normalization of data.
xData = stats.zscore(xData, axis = 1)
yData2 = yData.copy()
yData2[yData2<0.5] = 0
yData2[yData2>=0.5] = 1
xTrain, xTest, yTrain, yTest = train_test_split(np.array(xData), np.array(yData2), test_size = 0.3)

# Oversampling - Smoting
from imblearn.over_sampling import SMOTE
oversample = SMOTE()
X_smoted, y_smoted = oversample.fit_resample(xData, yData2)

"""# LOGISTIC REGRESSION"""

weights= logisticreg(X_smoted, y_smoted)
accuracy, precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC = testModel(weights,xTest,yTest)

print("Accuracy :",accuracy)

eva_list.append(dict([
    ('Model', 'LogReg'),
    ('Accuracy', round(accuracy, 2)),
    ('Presicion Positive', round(precisionPositive, 2)),
    ('Precision Negative', round(precisionNegative, 2)),
    ('Recall Positive', round(recallPositive, 2)),
    ('Recall Negative', round(recallNegative, 2)),
    ('F1score Positive', round(fScorePositive, 2)),
    ('F1score Negative', round(fScoreNegative, 2)),
    ('AUC', round(AUC, 2))
     ]))

"""# SVM [With various kernel functions]"""

# Linear kernel
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
params_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'kernel':['linear'] 
}
svc = GridSearchCV(SVC(), params_grid)
svc.fit(X_smoted, y_smoted)
y_pred1 = svc.predict(xTest)
print(svc.best_estimator_)

accuracy = accuracy_score(y_pred1,yTest)
precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative,AUC = accuracyMeasures(y_pred1,yTest)

print("Accuracy :",accuracy)

eva_list.append(dict([
    ('Model', 'SVM (Linear)'),
    ('Accuracy', round(accuracy, 2)),
    ('Presicion Positive', round(precisionPositive, 2)),
    ('Precision Negative', round(precisionNegative, 2)),
    ('Recall Positive', round(recallPositive, 2)),
    ('Recall Negative', round(recallNegative, 2)),
    ('F1score Positive', round(fScorePositive, 2)),
    ('F1score Negative', round(fScoreNegative, 2)),
    ('AUC', round(AUC, 2))
     ]))

#Polynomial kernel
from sklearn.svm import SVC
params_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'kernel':['poly'] 
}
svc = GridSearchCV(SVC(), params_grid)
svc.fit(X_smoted, y_smoted)
y_pred2 = svc.predict(xTest)
print(svc.best_estimator_)

accuracy = accuracy_score(y_pred2,yTest)

precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC = accuracyMeasures(y_pred2,yTest)

print("Accuracy :",accuracy)

eva_list.append(dict([
    ('Model', 'SVM (Poly)'),
    ('Accuracy', round(accuracy, 2)),
    ('Presicion Positive', round(precisionPositive, 2)),
    ('Precision Negative', round(precisionNegative, 2)),
    ('Recall Positive', round(recallPositive, 2)),
    ('Recall Negative', round(recallNegative, 2)),
    ('F1score Positive', round(fScorePositive, 2)),
    ('F1score Negative', round(fScoreNegative, 2)),
    ('AUC', round(AUC, 2))
     ]))

#Radial Basis Function kernel
from sklearn.svm import SVC
params_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'kernel':['rbf'] 
}
svc = GridSearchCV(SVC(), params_grid)
svc.fit(X_smoted, y_smoted)
y_pred3 = svc.predict(xTest)
print(svc.best_estimator_)

accuracy = accuracy_score(y_pred3,yTest)

precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC = accuracyMeasures(y_pred3,yTest)

print("Accuracy :",accuracy)

eva_list.append(dict([
    ('Model', 'SVM (rbf kernel)'),
    ('Accuracy', round(accuracy, 2)),
    ('Presicion Positive', round(precisionPositive, 2)),
    ('Precision Negative', round(precisionNegative, 2)),
    ('Recall Positive', round(recallPositive, 2)),
    ('Recall Negative', round(recallNegative, 2)),
    ('F1score Positive', round(fScorePositive, 2)),
    ('F1score Negative', round(fScoreNegative, 2)),
    ('AUC', round(AUC, 2))
     ]))

#Sigmoid kernel
from sklearn.svm import SVC
params_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],
    'kernel':['sigmoid'] 
}
svc = GridSearchCV(SVC(), params_grid)
svc.fit(X_smoted, y_smoted)
y_pred4 = svc.predict(xTest)
print(svc.best_estimator_)

accuracy = accuracy_score(y_pred4,yTest)

precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC = accuracyMeasures(y_pred4,yTest)

print("Accuracy :",accuracy)

eva_list.append(dict([
    ('Model', 'SVM (Sigmoid kernel)'),
    ('Accuracy', round(accuracy, 2)),
    ('Presicion Positive', round(precisionPositive, 2)),
    ('Precision Negative', round(precisionNegative, 2)),
    ('Recall Positive', round(recallPositive, 2)),
    ('Recall Negative', round(recallNegative, 2)),
    ('F1score Positive', round(fScorePositive, 2)),
    ('F1score Negative', round(fScoreNegative, 2)),
    ('AUC', round(AUC, 2))
     ]))

"""# DECISION TREE"""

from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
clf = DecisionTreeClassifier(random_state=0)
clf.fit(X_smoted, y_smoted)
y_preddc = clf.predict(xTest)
classname = ['Positive','Negative']
fig = plt.figure(figsize=(250,200))
tree.plot_tree(clf, 
                   feature_names=df.keys(),
                   class_names=classname,
                   filled=True)
fig.savefig("dtree.png")

accuracy = accuracy_score(y_preddc,yTest)

precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC = accuracyMeasures(y_preddc,yTest)

print("Accuracy :",accuracy)

eva_list.append(dict([
    ('Model', 'DecisionTree'),
    ('Accuracy', round(accuracy, 2)),
    ('Presicion Positive', round(precisionPositive, 2)),
    ('Precision Negative', round(precisionNegative, 2)),
    ('Recall Positive', round(recallPositive, 2)),
    ('Recall Negative', round(recallNegative, 2)),
    ('F1score Positive', round(fScorePositive, 2)),
    ('F1score Negative', round(fScoreNegative, 2)),
    ('AUC', round(AUC, 2))
     ]))

"""# RANDOM FOREST"""

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(n_estimators = 6, criterion = 'entropy', random_state = 0)
classifier.fit(X_smoted, y_smoted)
y_predt = classifier.predict(xTest)

from sklearn import tree
fig = plt.figure(figsize=(25,20))
fn=df.keys()
cn=["Confirmed","False Positive"]
fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=800)
tree.plot_tree(classifier.estimators_[0],
               feature_names = fn, 
               class_names=cn,
               filled = True);
fig.savefig('rf_individualtree.png')

accuracy = accuracy_score(y_predt,yTest)

precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC = accuracyMeasures(y_predt,yTest)

print("Accuracy :",accuracy)

eva_list.append(dict([
    ('Model', 'RandomForest'),
    ('Accuracy', round(accuracy, 2)),
    ('Presicion Positive', round(precisionPositive, 2)),
    ('Precision Negative', round(precisionNegative, 2)),
    ('Recall Positive', round(recallPositive, 2)),
    ('Recall Negative', round(recallNegative, 2)),
    ('F1score Positive', round(fScorePositive, 2)),
    ('F1score Negative', round(fScoreNegative, 2)),
    ('AUC', round(AUC, 2))
     ]))

"""# KNN"""

# Functions for knn
def getDistance(xData,xTestPoint):
  distances={}
  sortedDistances={}
  for i in range(0,len(xData)):
    distances[i]=np.linalg.norm(xData[i]-xTestPoint)
  sortedDistances={k: v for k, v in sorted(distances.items(), key=lambda item: item[1])}
  return sortedDistances

def knn(xData,xTest,yData,yTest,k):
  count0=0
  count1=0
  accuracy=0
  sortedDistances={}
  for j in range(0,len(xTest)):
    sortedDistances=getDistance(xData,xTest[j])
    for i in range(k):
      if yData[list(sortedDistances.keys())[i]]==0:
        count0+=1
      else:
        count1+=1
    if count1>count0:
      yhat= 0
    else:
      yhat= 1
    if yhat==yTest[j]:
      accuracy+=1
  print(accuracy)
  return accuracy

k=3
accuracy=knn(X_smoted,xTest,y_smoted,yTest,k)
print("Accuracy : ",accuracy/len(yTest))

"""# GAUSSIAN NAIVE BAYES"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB()
y_prednb = gnb.fit(X_smoted, y_smoted).predict(xTest)

accuracy = accuracy_score(y_prednb,yTest)

precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC = accuracyMeasures(y_prednb,yTest)

print("Accuracy :",accuracy)

eva_list.append(dict([
    ('Model', 'GaussianNB'),
    ('Accuracy', round(accuracy, 2)),
    ('Presicion Positive', round(precisionPositive, 2)),
    ('Precision Negative', round(precisionNegative, 2)),
    ('Recall Positive', round(recallPositive, 2)),
    ('Recall Negative', round(recallNegative, 2)),
    ('F1score Positive', round(fScorePositive, 2)),
    ('F1score Negative', round(fScoreNegative, 2)),
    ('AUC', round(AUC, 2))
     ]))

"""# HEIRARCHICAL CLUSTERING [AGGLOMERATIVE]"""

import scipy.cluster.hierarchy as shc
plt.figure(figsize=(20, 10))  
plt.title("Dendrograms")  
dend = shc.dendrogram(shc.linkage(xData, method='ward'))

from sklearn.preprocessing import StandardScaler, normalize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df)
X_normalized = normalize(X_scaled)
X_normalized = pd.DataFrame(X_normalized)

from sklearn.decomposition import PCA
pca = PCA(n_components = 2)
X_principal = pca.fit_transform(X_normalized)
X_principal = pd.DataFrame(X_principal)
X_principal.columns = ['P1', 'P2']

ac2 = AgglomerativeClustering(n_clusters = 3)
  
# Visualizing the clustering
plt.figure(figsize =(6, 6))
plt.scatter(X_principal['P1'], X_principal['P2'], 
           c = ac2.fit_predict(X_principal))
plt.show()

from sklearn.cluster import AgglomerativeClustering
shc = AgglomerativeClustering(n_clusters = 3, affinity = 'euclidean', linkage = 'ward')
shc = shc.fit_predict(xData)

"""# XGBoost"""

import xgboost as xgb
xgboost = xgb.XGBClassifier(silent=False, 
                      scale_pos_weight=1,
                      learning_rate=0.01,  
                      colsample_bytree = 0.4,
                      subsample = 0.8,
                      objective='binary:logistic', 
                      n_estimators=1000, 
                      reg_alpha = 0.3,
                      max_depth=4, 
                      gamma=10)

xgboost.fit(X_smoted, y_smoted)
y_predx = xgboost.predict(xTest)

accuracy = accuracy_score(y_predx,yTest)

precisionPositive, precisionNegative, recallPositive, recallNegative, fScorePositive, fScoreNegative, AUC = accuracyMeasures(y_predx,yTest)

eva_list.append(dict([
    ('Model', 'XGBoost'),
    ('Accuracy', round(accuracy, 2)),
    ('Presicion Positive', round(precisionPositive, 2)),
    ('Precision Negative', round(precisionNegative, 2)),
    ('Recall Positive', round(recallPositive, 2)),
    ('Recall Negative', round(recallNegative, 2)),
    ('F1score Positive', round(fScorePositive, 2)),
    ('F1score Negative', round(fScoreNegative, 2)),
    ('AUC', round(AUC, 2))
     ]))

"""# SUMMARY OF ALL MODELS"""

# Printing the evaluation results
results = pd.DataFrame(data=eva_list)
results = results[['Model', 'Accuracy', 'Presicion Positive', 'Precision Negative', 'Recall Positive', 'Recall Negative', 'F1score Positive', 'F1score Negative', 'AUC']]
results = results.sort_values(by='Accuracy', ascending=False)
results = results.set_index('Model')
results

"""# CONCLUSION

Decision tree and random forests gave the best accuracies.
Hence, machine learning algorithms can have extensive use in astronomical field. 

As observed, some models did fine to find possibly habitable planets, even without knowing the chemical properties.
"""